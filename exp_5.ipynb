{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Exp5 NLP basics with Built in stuff on colab**"
      ],
      "metadata": {
        "id": "wAVaikpnPwlU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDQnRvEmPtaT",
        "outputId": "63a93520-913c-4f09-fdd4-501c1a2979d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 1796 documents, 2 categories\n",
            "Sample text:\n",
            "genealogical \n",
            "old \n",
            "\n",
            "Well, since my wife is (in your gentle term) a \"bastard\", I can\n",
            "probably speak with a bit of authority on this. Any \"stigma\"\n",
            "associated with children conceived and/or born out of wedlock rests\n",
            "solely upon the parents--they've committed a sexual transgression for\n",
            "which they should...\n",
            "\n",
            "After preprocessing:\n",
            "genealogical old since wife your gentle can probably speak with bit authority any associated with children conceived born out wedlock rests solely upon the committed sexual transgression for which they should the child itself has priori limitations him the concept blaming the child for the sins one ...\n",
            "\n",
            "Training data: (1257, 1000), Test data: (539, 1000)\n",
            "\n",
            "Accuracy: 0.8182\n",
            "\n",
            "Classification Report:\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "           alt.atheism       0.80      0.77      0.79       235\n",
            "soc.religion.christian       0.83      0.85      0.84       304\n",
            "\n",
            "              accuracy                           0.82       539\n",
            "             macro avg       0.82      0.81      0.81       539\n",
            "          weighted avg       0.82      0.82      0.82       539\n",
            "\n",
            "\n",
            "Top 10 words for 'alt.atheism':\n",
            "say, know, religion, atheism, does, just, think, people, don, god\n",
            "\n",
            "Top 10 words for 'soc.religion.christian':\n",
            "think, does, christians, know, christ, people, christian, church, jesus, god\n",
            "\n",
            "Document Classification:\n",
            "Text: 'I believe in the power of faith and Jesus Christ a...'\n",
            "Predicted: soc.religion.christian\n",
            "\n",
            "Text: 'Religion has no scientific basis and relies on bli...'\n",
            "Predicted: alt.atheism\n",
            "\n",
            "NLP operations demo complete!\n"
          ]
        }
      ],
      "source": [
        "# Concise NLP Operations Demo\n",
        "# --------------------------\n",
        "\n",
        "# Essential imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 1. Load a subset of the 20 Newsgroups dataset (just 2 categories for simplicity)\n",
        "categories = ['alt.atheism', 'soc.religion.christian']\n",
        "newsgroups = fetch_20newsgroups(\n",
        "    subset='all',\n",
        "    categories=categories,\n",
        "    shuffle=True,\n",
        "    random_state=42,\n",
        "    remove=('headers', 'footers', 'quotes')\n",
        ")\n",
        "\n",
        "# Quick dataset overview\n",
        "print(f\"Dataset: {len(newsgroups.data)} documents, {len(categories)} categories\")\n",
        "print(f\"Sample text:\\n{newsgroups.data[0][:300]}...\\n\")\n",
        "\n",
        "# 2. Simple text preprocessing function\n",
        "def basic_preprocess(text):\n",
        "    # Convert to lowercase and remove punctuation/digits using a single comprehension\n",
        "    return ' '.join(word.lower() for word in text.split()\n",
        "                   if word.isalpha() and len(word) > 2)\n",
        "\n",
        "# Process a sample\n",
        "sample_processed = basic_preprocess(newsgroups.data[0])\n",
        "print(f\"After preprocessing:\\n{sample_processed[:300]}...\\n\")\n",
        "\n",
        "# 3. Text vectorization - TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "X = tfidf.fit_transform(newsgroups.data)\n",
        "y = newsgroups.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "print(f\"Training data: {X_train.shape}, Test data: {X_test.shape}\")\n",
        "\n",
        "# 4. Train a classifier\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# 5. Evaluate\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=categories))\n",
        "\n",
        "# 6. Feature importance - most distinctive words for each category\n",
        "feature_names = np.array(tfidf.get_feature_names_out())\n",
        "\n",
        "def show_top_features(classifier, feature_names, class_labels, n=10):\n",
        "    for i, class_label in enumerate(class_labels):\n",
        "        top_indices = np.argsort(classifier.feature_log_prob_[i])[-n:]\n",
        "        top_features = feature_names[top_indices]\n",
        "        print(f\"\\nTop {n} words for '{class_label}':\")\n",
        "        print(\", \".join(top_features))\n",
        "\n",
        "show_top_features(clf, feature_names, categories)\n",
        "\n",
        "# 7. Classify a new document\n",
        "new_docs = [\n",
        "    \"I believe in the power of faith and Jesus Christ as our savior.\",\n",
        "    \"Religion has no scientific basis and relies on blind faith.\"\n",
        "]\n",
        "\n",
        "# Vectorize and predict\n",
        "new_docs_tfidf = tfidf.transform(new_docs)\n",
        "predictions = clf.predict(new_docs_tfidf)\n",
        "\n",
        "print(\"\\nDocument Classification:\")\n",
        "for doc, pred in zip(new_docs, predictions):\n",
        "    print(f\"Text: '{doc[:50]}...'\")\n",
        "    print(f\"Predicted: {categories[pred]}\\n\")\n",
        "\n",
        "print(\"NLP operations demo complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CcXj-fitPuBc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}